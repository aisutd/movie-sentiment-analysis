{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GLHmU5li8PM"
      },
      "source": [
        "#**Abstract** [incomplete]\r\n",
        "\r\n",
        "In a world full of different products and services offered by many different companies, it is natural for people to be curious about the quality of a certain solution. Moreover, companies want to sell their products and services \r\n",
        "\r\n",
        "to the best of their abilities. In doing so, not only do they retain their customer base, but also gain a profit. To deliver a better product, it is vital to understand how the masses perceive the current version of the solution. But it is tedious to analyze thousands of human written reviews manually especially withholding bias. To overcome this problem, we can use ML (Machine Learning) and NLP (Natural Language Processing) to automate the analysis process and have a general idea of how a product is perceived. \r\n",
        "\r\n",
        "Our project focuses on sentiment analysis of movie reviews. This allows an individual to get closer to the consensus when it comes to the quality of the movie that is being reviewed. This data can be used by anyone from the makers of the film to individuals who are simply interested in the movie to gauge what people think of it.\r\n",
        "\r\n",
        "Similar process of sentiment analysis can be applied for any product, service or solution for evaluation, aiding further refinements.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4wxFjPFmazg"
      },
      "source": [
        "# **Step 1: The Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmyE9N9jmlX0"
      },
      "source": [
        "[**IMDB Dataset of 50K Movie Reviews**](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) \r\n",
        "\r\n",
        "Columns:\r\n",
        "\r\n",
        "\r\n",
        "1.   Review (String)\r\n",
        "2.   Sentiment (String)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQmmR7-1zdA"
      },
      "source": [
        "# **Step 2: Importing Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYG_YINOjj5S"
      },
      "source": [
        "**Pandas** \r\n",
        "\r\n",
        "Open source data analysis and manipulation tool.\r\n",
        "\r\n",
        "**NumPy** \r\n",
        "\r\n",
        "High performance numerical computation library inspired by MatLab and Native C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VIh9Qcx10Ot"
      },
      "source": [
        "# Data manipulation\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THOx5yzEBj6n"
      },
      "source": [
        "**NLTK (Natural Language Toolkit)** \r\n",
        "\r\n",
        "A set of libraries and programs used for symbolic and statistical natural language processing of English.\r\n",
        "\r\n",
        "**Scikit-learn** \r\n",
        "\r\n",
        "Machine Learning library that has various classification, regression and cluster algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubezvA3y3b4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415e8689-3468-41d8-d3dd-77b19bc8c730"
      },
      "source": [
        "# Importing libraries\r\n",
        "import nltk\r\n",
        "\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO3K2FZx38uC"
      },
      "source": [
        "# Machine learning\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFRQ0jL-lMr0"
      },
      "source": [
        "# **Step 3: Stopwords**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8wBPJt9hs_a"
      },
      "source": [
        "**Stopwords**\r\n",
        "\r\n",
        "A set of commonly used words in a language (determiners, coordinate conjunctions, prepositions. etc).\r\n",
        "\r\n",
        "These word are filtered out before or after processing natural language data. This allows us to focus on the important words.\r\n",
        "\r\n",
        "Example: There is **an** umbrella.\r\n",
        "\r\n",
        "Popular Stopword Lists:\r\n",
        "\r\n",
        "1. [Terrier Stopword List](https://github.com/kavgan/stop-words/blob/master/terrier-stop.txt)\r\n",
        "\r\n",
        "2. [Snowball Stopword List](http://snowball.tartarus.org/algorithms/english/stop.txt)\r\n",
        "\r\n",
        "3. [Stopword Lists for 19 Languages](https://www.kaggle.com/rtatman/stopword-lists-for-19-languages)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRFJgU4kjasf"
      },
      "source": [
        "# Stopwords (using NLTK for list)\r\n",
        "stopword_list = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQRq4Dj8sEMw"
      },
      "source": [
        "# **Step 4: Preprocessing the Textual Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odz-9wBesx5S"
      },
      "source": [
        "\r\n",
        "\r\n",
        " **Casing**\r\n",
        "\r\n",
        " Converting the textual data to either all upper or lower case.\r\n",
        "\r\n",
        " **Noise Removal**\r\n",
        "\r\n",
        " Removal of character digits and other pieces of data that can interfere with text analysis.\r\n",
        "\r\n",
        "In this project we removed:\r\n",
        "\r\n",
        "\r\n",
        "*   URLs\r\n",
        "*   Punctuation\r\n",
        "*   Symbols\r\n",
        "\r\n",
        "\r\n",
        " **Tokenization**\r\n",
        "\r\n",
        " A method of separating texts into smaller units called tokens. \r\n",
        "\r\n",
        " **Stopword Removal**\r\n",
        " \r\n",
        " Refer to previous text block.\r\n",
        "\r\n",
        " **Text Normalization**\r\n",
        "  *   **Stemming**\r\n",
        "\r\n",
        "  Stemming programs are commonly referred to as stemming algorithms or stemmers. In this process you cutt prefixes and suffixes to produce a base word. This is technique is effective but contains certain limitations.\r\n",
        "\r\n",
        "    **Example:** fishing -> fish\r\n",
        "\r\n",
        "\r\n",
        "  *   **Lemmatization**\r\n",
        "  \r\n",
        "  What is a lemma?\r\n",
        "\r\n",
        "  In morphology and lexicography, a lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words (headword). In English, for example, run, runs, ran and running are forms of the same lexeme, with run as the lemma by which they are indexed.\r\n",
        "\r\n",
        "  Lemmatization is the process of converting words into lemmas by considering the morphological analysis of the word.\r\n",
        "\r\n",
        "    **Example:** am, are, is -> be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX6Omj4Ak24y"
      },
      "source": [
        "# Function to do all the preprocesssing\r\n",
        "def preprocess_review(review):\r\n",
        "\r\n",
        "    # Casing\r\n",
        "    review = review.lower()\r\n",
        "\r\n",
        "    # Remove URLs\r\n",
        "    review = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", review, flags = re.MULTILINE)\r\n",
        "\r\n",
        "    # Removing punctuation and other symbols\r\n",
        "    review = review.translate(str.maketrans(\"\", \"\", string.punctuation))\r\n",
        "    review = re.sub(r'\\@\\w+|\\#', \"\", review)\r\n",
        "\r\n",
        "    # Tokenize\r\n",
        "    review_tokens = word_tokenize(review)\r\n",
        "\r\n",
        "    # Remove stopwords\r\n",
        "    filtered_words = [word for word in review_tokens if word not in stopword_list]\r\n",
        "\r\n",
        "    # Stemming\r\n",
        "    #ps = PorterStemmer()\r\n",
        "    #stemmed_words = [ps.stem(w) for w in filtered_words]\r\n",
        "\r\n",
        "    # Lemmatizing\r\n",
        "    lemmatizer = WordNetLemmatizer()\r\n",
        "    lemma_words = [lemmatizer.lemmatize(w, pos = 'a') for w in filtered_words]\r\n",
        "\r\n",
        "    return \" \".join(lemma_words)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOzJG5orxXTr"
      },
      "source": [
        " **Lambda Function**\r\n",
        "\r\n",
        "  Single-line function declared with no name, which can have any number of arguments, but it can only have one expression. Such a function is capable of behaving similarly to a regular function declared using the Python's def keyword. Often times a lambda function is passed as an argument to another function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J84pwONsxYQe",
        "outputId": "dd61e8c8-d0cb-4d70-efcf-4db97f80e428"
      },
      "source": [
        "# Lambda function for preprocessing function\r\n",
        "cleaned_text = lambda x: preprocess_review(x)\r\n",
        "\r\n",
        "\r\n",
        "preprocess_review(\"Hello, this is a Test Line #@ ...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello test line'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cgF2TwkOtc"
      },
      "source": [
        "# **Step 5: Uploading the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYuWTFhozeCs"
      },
      "source": [
        "How to mount google drive in colab:\r\n",
        "\r\n",
        "https://www.youtube.com/watch?v=zYHVzPV3djs\r\n",
        "\r\n",
        "https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166\r\n",
        "\r\n",
        "https://colab.research.google.com/notebooks/io.ipynb\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EmE1ZTJ0zoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbbf9de-b280-46cb-e187-3058df2e981f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH0JMcCp0r_2"
      },
      "source": [
        "**Implementation of preprocessing function:**\r\n",
        "\r\n",
        "We use the read_csv() method from the Pandas library to read the dataset.\r\n",
        "\r\n",
        "We then use our lambda function to clean each text and add the new processed text to a column named \"cleaned_review\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOwbBhADgbK-",
        "outputId": "fb040696-957f-4f07-feeb-c762a40a4209"
      },
      "source": [
        "import io\r\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Sentiment_Analysis/Colab Notebooks/IMDB_Dataset.csv')\r\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ZvCYQElemE1y",
        "outputId": "4c0a89ea-430f-4f16-a00c-883786dd2d10"
      },
      "source": [
        "# Looking at the raw data of the dataset\r\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>cleaned_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production br br filming tech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically theres family little boy jake thinks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter matteis love time money visually stunni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>probably alltime favorite movie story selfless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sure would like see resurrection dated seahunt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "      <td>show amazing fresh innovative idea 70s first a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "      <td>encouraged positive comments film looking forw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>like original gut wrenching laughter like movi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                     cleaned_review\n",
              "0  One of the other reviewers has mentioned that ...  ...  one reviewers mentioned watching 1 oz episode ...\n",
              "1  A wonderful little production. <br /><br />The...  ...  wonderful little production br br filming tech...\n",
              "2  I thought this was a wonderful way to spend ti...  ...  thought wonderful way spend time hot summer we...\n",
              "3  Basically there's a family where a little boy ...  ...  basically theres family little boy jake thinks...\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...  petter matteis love time money visually stunni...\n",
              "5  Probably my all-time favorite movie, a story o...  ...  probably alltime favorite movie story selfless...\n",
              "6  I sure would like to see a resurrection of a u...  ...  sure would like see resurrection dated seahunt...\n",
              "7  This show was an amazing, fresh & innovative i...  ...  show amazing fresh innovative idea 70s first a...\n",
              "8  Encouraged by the positive comments about this...  ...  encouraged positive comments film looking forw...\n",
              "9  If you like original gut wrenching laughter yo...  ...  like original gut wrenching laughter like movi...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-d_J9V2mJOW",
        "outputId": "61230c14-5ff1-428b-fcc4-ad96de42969f"
      },
      "source": [
        "# Information on the dataset\r\n",
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   review          50000 non-null  object\n",
            " 1   sentiment       50000 non-null  object\n",
            " 2   cleaned_review  50000 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVoIO67qqEe"
      },
      "source": [
        "# Running our lambda function on the dataset\r\n",
        "dataset['cleaned_review'] = pd.DataFrame(dataset.review.apply(cleaned_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "7rZsiZ2LSvr8",
        "outputId": "df524f71-074a-4fdf-f7e2-afc7a51e1d80"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>cleaned_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production br br filming tech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically theres family little boy jake thinks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter matteis love time money visually stunni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>probably alltime favorite movie story selfless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sure would like see resurrection dated seahunt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "      <td>show amazing fresh innovative idea 70s first a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "      <td>encouraged positive comments film looking forw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>like original gut wrenching laughter like movi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                     cleaned_review\n",
              "0  One of the other reviewers has mentioned that ...  ...  one reviewers mentioned watching 1 oz episode ...\n",
              "1  A wonderful little production. <br /><br />The...  ...  wonderful little production br br filming tech...\n",
              "2  I thought this was a wonderful way to spend ti...  ...  thought wonderful way spend time hot summer we...\n",
              "3  Basically there's a family where a little boy ...  ...  basically theres family little boy jake thinks...\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...  petter matteis love time money visually stunni...\n",
              "5  Probably my all-time favorite movie, a story o...  ...  probably alltime favorite movie story selfless...\n",
              "6  I sure would like to see a resurrection of a u...  ...  sure would like see resurrection dated seahunt...\n",
              "7  This show was an amazing, fresh & innovative i...  ...  show amazing fresh innovative idea 70s first a...\n",
              "8  Encouraged by the positive comments about this...  ...  encouraged positive comments film looking forw...\n",
              "9  If you like original gut wrenching laughter yo...  ...  like original gut wrenching laughter like movi...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh_bPdPKT6wv"
      },
      "source": [
        "# **The Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpJrl-SeJEpu"
      },
      "source": [
        "In the dataset, we have our **independent variables** (review) and **dependent variable** (sentiment). While most of the data will be used for teaching the model, we wil keep some aside for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLxjbaOuT52t",
        "outputId": "ac5e7417-0cd8-4231-b76b-ea4bc2e538d6"
      },
      "source": [
        "review = dataset.cleaned_review\r\n",
        "sentiment = dataset.sentiment\r\n",
        "\r\n",
        "IV_train, IV_test, DV_train, DV_test = train_test_split(review, sentiment, test_size = 0.1, random_state = 5)\r\n",
        "\r\n",
        "print('IV_train :', len(IV_train))\r\n",
        "print('IV_test :', len(IV_test))\r\n",
        "print('DV_train :', len(DV_train))\r\n",
        "print('DV_test :', len(DV_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IV_train : 45000\n",
            "IV_test : 5000\n",
            "DV_train : 45000\n",
            "DV_test : 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-6AxIIVKs1N"
      },
      "source": [
        "### **Term Frequency-Inverse Document Frequency (TF-IDC) Vectorization**\n",
        "\n",
        "**TF-IDF**\n",
        "\n",
        "A statistical measure that evaluates how relevant a word is to a document in a collection of documents.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Term Frequency**\n",
        "\n",
        "The number of times a certain term occurs in a sentence with respect to the total number of terms in the sentence.\n",
        "\n",
        "\n",
        "TF = (no. on times a word repeats in a sentence) / (no. of words in a sentence)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Inverse Document Frequency**\n",
        "\n",
        "The rareness of a term.\n",
        "\n",
        "IDF = log((no. of sentences) / (no. of sentences containing words))\n",
        "\n",
        "<br>\n",
        "\n",
        "**Vectorizing**\n",
        "\n",
        "After using TF-IDF on our reviews, we convert them into vectors with respect to the sentences.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "###**Logistic Regression using solver lbfgs**\n",
        "**Regression**\n",
        "\n",
        "A type of predictive modeling technique which is used to find the relationship between a dependent variable with one or multiple independent variables.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "A classification algorithm used to predict binary outcome based on a set of independent variables.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "###**Pipieline**\n",
        "\n",
        "A pipeline enables us to assemble several steps that can be cross-validated tegether while setting different parameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL40UFWfWpYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bc4d16-3e72-4c9a-de58-307393da677e"
      },
      "source": [
        "# Preparing TF-IDF vectorizer\r\n",
        "tvec = TfidfVectorizer()\r\n",
        "clf2 = LogisticRegression(solver = 'lbfgs')\r\n",
        "\r\n",
        "# Building our pipeline\r\n",
        "model = Pipeline([('vectorizer', tvec), ('classifier', clf2)])\r\n",
        "model.fit(IV_train, DV_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtYYajUUY3u0",
        "outputId": "47f2cac5-b484-4d13-c617-2782fa84e4ec"
      },
      "source": [
        "predictions = model.predict(IV_test)\r\n",
        "confusion_matrix(predictions, DV_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2152,  227],\n",
              "       [ 292, 2329]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDl_5DbgdRQY",
        "outputId": "6898dfb4-0fad-4a33-b9c1-77a2358cae64"
      },
      "source": [
        "print(\"Accuracy : \", accuracy_score(predictions, DV_test))\r\n",
        "print(\"Percision : \", precision_score(predictions, DV_test, average = 'weighted'))\r\n",
        "print(\"Recall : \", recall_score(predictions, DV_test, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8962\n",
            "Percision :  0.8965986531482036\n",
            "Recall :  0.8962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yKzQhvVZi7i"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbDwMzvGZmuD",
        "outputId": "a95cb51d-65e2-476a-8a85-265405c60270"
      },
      "source": [
        "example = [\"DONT HAPPY POSITIVE\"] # PUT IN EXAMPLE HERE\r\n",
        "result = model.predict(example)\r\n",
        "\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}