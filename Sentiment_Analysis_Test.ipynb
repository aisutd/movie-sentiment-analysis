{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQmmR7-1zdA"
      },
      "source": [
        "# **Step 1: Importing Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYG_YINOjj5S"
      },
      "source": [
        "**Pandas** \r\n",
        "\r\n",
        "Open source data analysis and manipulation tool.\r\n",
        "\r\n",
        "**NumPy** \r\n",
        "\r\n",
        "High performance numerical computation library inspired by MatLab and Native C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VIh9Qcx10Ot"
      },
      "source": [
        "# Data manipulation\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import string"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THOx5yzEBj6n"
      },
      "source": [
        "**NLTK (Natural Language Toolkit)** \r\n",
        "\r\n",
        "A set of libraries and programs used for symbolic and statistical natural language processing of English.\r\n",
        "\r\n",
        "**Scikit-learn** \r\n",
        "\r\n",
        "Machine Learning library that has various classification, regression and cluster algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubezvA3y3b4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb249fb-daf6-4ca9-8b27-591c2ee8a090"
      },
      "source": [
        "# Importing libraries\r\n",
        "import nltk\r\n",
        "\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO3K2FZx38uC"
      },
      "source": [
        "# Machine learning\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFRQ0jL-lMr0"
      },
      "source": [
        "# **Step 2: Stopwords**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8wBPJt9hs_a"
      },
      "source": [
        "**Stopwords**\r\n",
        "\r\n",
        "A set of commonly used words in a language (determiners, coordinate conjunctions, prepositions. etc).\r\n",
        "\r\n",
        "These word are filtered out before or after processing natural language data. This allows us to focus on the important words.\r\n",
        "\r\n",
        "Example: There is **an** umbrella.\r\n",
        "\r\n",
        "Popular Stopword Lists:\r\n",
        "\r\n",
        "1. [Terrier Stopword List](https://github.com/kavgan/stop-words/blob/master/terrier-stop.txt)\r\n",
        "\r\n",
        "2. [Snowball Stopword List](http://snowball.tartarus.org/algorithms/english/stop.txt)\r\n",
        "\r\n",
        "3. [Stopword Lists for 19 Languages](https://www.kaggle.com/rtatman/stopword-lists-for-19-languages)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRFJgU4kjasf"
      },
      "source": [
        "# Stopwords (using NLTK for list)\r\n",
        "stopword_list = set(stopwords.words('english'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4wxFjPFmazg"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# **Step 3: Loading Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmyE9N9jmlX0"
      },
      "source": [
        "[**IMDB Dataset of 50K Movie Reviews**](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) \r\n",
        "\r\n",
        "Columns:\r\n",
        "\r\n",
        "\r\n",
        "1.   Review (String)\r\n",
        "2.   Sentiment (String)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krUx3mwerEGd"
      },
      "source": [
        "**load_dataset**\r\n",
        "\r\n",
        "Function that reads dataset to build a dataframe.\r\n",
        "\r\n",
        "Parameters:\r\n",
        "\r\n",
        "*   filepath: path to the dataset (CVS file).\r\n",
        "*   cols: columns of the dataset.\r\n",
        "\r\n",
        "Return:\r\n",
        "*   df: dataframe from dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHWM3gTo17g"
      },
      "source": [
        "def load_dataset(filepath, cols):\r\n",
        "    df = pd.read_csv(filepath, encoding = 'latin-1')\r\n",
        "    df.columns = cols \r\n",
        "    return df"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQRq4Dj8sEMw"
      },
      "source": [
        "# **Step 4: Preprocessing the Textual Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odz-9wBesx5S"
      },
      "source": [
        "\r\n",
        "\r\n",
        " **Casing**\r\n",
        "\r\n",
        " Converting the textual data to either all upper or lower case.\r\n",
        "\r\n",
        " **Noise Removal** \r\n",
        "\r\n",
        " **Tokenization**\r\n",
        "\r\n",
        " **Stopword Removal**\r\n",
        "\r\n",
        " **Text Normalization**\r\n",
        "  *   Stemming\r\n",
        "  *   Lemmatization\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FX6Omj4Ak24y",
        "outputId": "c8871d6c-f4bb-4e3a-e985-19d10b76f4de"
      },
      "source": [
        "# Function to do all the preprocesssing\r\n",
        "def preprocess_review(review):\r\n",
        "\r\n",
        "    # Casing\r\n",
        "    review = review.lower()\r\n",
        "\r\n",
        "    # Remove URLs\r\n",
        "    review = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", review, flags = re.MULTILINE)\r\n",
        "\r\n",
        "    # Removing punctuation and other symbols\r\n",
        "    review = review.translate(str.maketrans(\"\", \"\", string.punctuation))\r\n",
        "    review = re.sub(r'\\@\\w+|\\#', \"\", review)\r\n",
        "\r\n",
        "    # Remove stopwords\r\n",
        "    review_tokens = word_tokenize(review)\r\n",
        "    filtered_words = [word for word in review_tokens if word not in stopword_list]\r\n",
        "\r\n",
        "    # Stemming\r\n",
        "    ps = PorterStemmer()\r\n",
        "    stemmed_words = [ps.stem(w) for w in filtered_words]\r\n",
        "\r\n",
        "    # Lemmatizing\r\n",
        "    lemmatizer = WordNetLemmatizer()\r\n",
        "    lemma_words = [lemmatizer.lemmatize(w, pos = 'a') for w in stemmed_words]\r\n",
        "\r\n",
        "    return \" \".join(lemma_words)\r\n",
        "\r\n",
        "\r\n",
        "cleaned_text = lambda x: preprocess_review(x)\r\n",
        "\r\n",
        "\r\n",
        "preprocess_review(\"Hello, this is a Test Line #@ ...\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello test line'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r81LDwZQjFd"
      },
      "source": [
        "# **Step 5: Vectorization of Textual Data**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHKbEoA0Q9hN"
      },
      "source": [
        "# Function to vectorize our data\r\n",
        "def get_feature_vector(train_fit):\r\n",
        "    vector = TfidfVectorizer(sublinear_tf = True)\r\n",
        "    vector.fit(train_fit)\r\n",
        "    return vector"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cgF2TwkOtc"
      },
      "source": [
        "# **Step 6: Uploading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EmE1ZTJ0zoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603d3b2f-1d7e-4051-e181-4fef96680878"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOwbBhADgbK-",
        "outputId": "b9f8122e-7f80-4628-bcc5-4a5c20ea91dc"
      },
      "source": [
        "import io\r\n",
        "dataset = pd.read_csv('IMDB Dataset.csv')\r\n",
        "dataset.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZvCYQElemE1y",
        "outputId": "2a689228-118c-4370-824a-eca3c306628a"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-d_J9V2mJOW",
        "outputId": "5188fc59-43ca-4b4b-aecb-797798b22282"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVoIO67qqEe"
      },
      "source": [
        "dataset['cleaned_review'] = pd.DataFrame(dataset.review.apply(cleaned_text))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7rZsiZ2LSvr8",
        "outputId": "0286701b-acd0-44f1-8b42-937e6edcd292"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>cleaned_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonder littl product br br film techniqu unass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonder way spend time hot summer weeke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basic there famili littl boy jake think there ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei love time money visual stun film...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                     cleaned_review\n",
              "0  One of the other reviewers has mentioned that ...  ...  one review mention watch 1 oz episod youll hoo...\n",
              "1  A wonderful little production. <br /><br />The...  ...  wonder littl product br br film techniqu unass...\n",
              "2  I thought this was a wonderful way to spend ti...  ...  thought wonder way spend time hot summer weeke...\n",
              "3  Basically there's a family where a little boy ...  ...  basic there famili littl boy jake think there ...\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...  petter mattei love time money visual stun film...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh_bPdPKT6wv"
      },
      "source": [
        "# **The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLxjbaOuT52t",
        "outputId": "617f0708-287a-4870-f222-23db8dc4ad05"
      },
      "source": [
        "review = dataset.cleaned_review\r\n",
        "sentiment = dataset.sentiment\r\n",
        "\r\n",
        "IV_train, IV_test, DV_train, DV_test = train_test_split(review, sentiment, test_size = 0.1, random_state = 5)\r\n",
        "\r\n",
        "print('IV_train :', len(IV_train))\r\n",
        "print('IV_test :', len(IV_test))\r\n",
        "print('DV_train :', len(DV_train))\r\n",
        "print('DV_test :', len(DV_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IV_train : 45000\n",
            "IV_test : 5000\n",
            "DV_train : 45000\n",
            "DV_test : 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL40UFWfWpYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b4a0d4-b6f7-4665-c1dd-6c8e4669437d"
      },
      "source": [
        "tvec = TfidfVectorizer()\r\n",
        "clf2 = LogisticRegression(solver = 'lbfgs')\r\n",
        "\r\n",
        "model = Pipeline([('vectorizer', tvec), ('classifier', clf2)])\r\n",
        "model.fit(IV_train, DV_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtYYajUUY3u0",
        "outputId": "65f92600-cd99-4869-c59f-637eb770c5c2"
      },
      "source": [
        "predictions = model.predict(IV_test)\r\n",
        "confusion_matrix(predictions, DV_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2155,  245],\n",
              "       [ 289, 2311]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDl_5DbgdRQY",
        "outputId": "0a084a08-b6e1-42d0-cbb5-b1857165dead"
      },
      "source": [
        "print(\"Accuracy : \", accuracy_score(predictions, DV_test))\r\n",
        "print(\"Percision : \", precision_score(predictions, DV_test, average = 'weighted'))\r\n",
        "print(\"Recall : \", recall_score(predictions, DV_test, average = 'weighted'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8932\n",
            "Percision :  0.8933970837207278\n",
            "Recall :  0.8932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yKzQhvVZi7i"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbDwMzvGZmuD",
        "outputId": "1f76d92f-2996-49d0-a485-4263f424fa9b"
      },
      "source": [
        "example = [\"i am very unhappy after watching this\"]\r\n",
        "result = model.predict(example)\r\n",
        "\r\n",
        "print(result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}